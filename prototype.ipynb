{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilia/.venvs/py3/lib/python3.5/site-packages/ggplot/utils.py:81: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access Timestamp as pandas.Timestamp\n",
      "  pd.tslib.Timestamp,\n",
      "/home/ilia/.venvs/py3/lib/python3.5/site-packages/ggplot/stats/smoothers.py:4: FutureWarning: The pandas.lib module is deprecated and will be removed in a future version. These are private functions and can be accessed from pandas._libs.lib instead\n",
      "  from pandas.lib import Timestamp\n",
      "/home/ilia/.venvs/py3/lib/python3.5/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from itertools import starmap, chain\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import ggplot\n",
    "from fn import F\n",
    "\n",
    "from chempred.chemdner import read_abstracts, read_annotations, pair, annotate_abstract\n",
    "from chempred import preprocessing as pp\n",
    "import prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 5\n",
    "\n",
    "abstracts_train = read_abstracts(\"chemdner_corpus/training.abstracts.txt\")\n",
    "anno_train = read_annotations(\"chemdner_corpus/training.annotations.txt\")\n",
    "pairs_train = list(zip(abstracts_train, pair(abstracts_train, anno_train)))\n",
    "annotated_abstracts_train = list(starmap(F(annotate_abstract, guided=True), pairs_train))\n",
    "\n",
    "abstracts_test = read_abstracts(\"chemdner_corpus/evaluation.abstracts.txt\")\n",
    "anno_test = read_annotations(\"chemdner_corpus/evaluation.annotations.txt\")\n",
    "pairs_test = list(zip(abstracts_test, pair(abstracts_test, anno_test)))\n",
    "annotated_abstracts_test = list(starmap(F(annotate_abstract, guided=True), pairs_test))\n",
    "\n",
    "pos_cls = Counter(\n",
    "    r[-1] for r in chain.from_iterable(anno for _, anno in anno_train + anno_test)\n",
    ")\n",
    "\n",
    "# TODO rename generate_training_samples\n",
    "samples_train, cls_train = pp.join_tokens_in_samples(\n",
    "    *pp.generate_training_samples(annotated_abstracts_train, pos_cls, window, False))\n",
    "samples_test, cls_test = pp.join_tokens_in_samples(\n",
    "    *pp.generate_training_samples(annotated_abstracts_test, pos_cls, window, False))\n",
    "\n",
    "max_sample_len = max(map(len, samples_train+samples_test))\n",
    "\n",
    "padded_samples_train, padded_cls_train, masks_train = pp.pad(samples_train, cls_train, \n",
    "                                                             max_sample_len)\n",
    "padded_samples_test, padded_cls_test, masks_test = pp.pad(samples_test, cls_test, \n",
    "                                                          max_sample_len)\n",
    "\n",
    "onehot_samples_train, onehot_cls_train = map(\n",
    "    pp.encode_one_hot, [padded_samples_train, padded_cls_train])\n",
    "masked_samples_train = pp.mask_array(onehot_samples_train, masks_train)\n",
    "masked_cls_train = pp.mask_array(onehot_cls_train, masks_train)\n",
    "\n",
    "onehot_samples_test, onehot_cls_test = map(\n",
    "    pp.encode_one_hot, [padded_samples_test, padded_cls_test])\n",
    "masked_samples_test = pp.mask_array(onehot_samples_test, masks_test)\n",
    "masked_cls_test = pp.mask_array(onehot_cls_test, masks_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "635"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sample_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34, 11],\n",
       "       [36, 11],\n",
       "       [33, 11],\n",
       "       [29, 11],\n",
       "       [29, 11],\n",
       "       [26,  9],\n",
       "       [24,  9],\n",
       "       [24,  9],\n",
       "       [18,  9],\n",
       "       [22,  9]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class_counts = np.vstack([np.unique(cls, return_counts=True)[1] for cls in \n",
    "#                           (padded_cls[mask] for padded_cls, mask in zip(padded_classes, masks))])\n",
    "# class_counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((143616, 635, 240), (123380, 635, 240))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_samples_train.shape, masked_samples_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as k\n",
    "from keras import losses\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143616 samples, validate on 123380 samples\n",
      "Epoch 1/30\n",
      "  2600/143616 [..............................] - ETA: 6727s - loss: 0.6857 - acc: 0.6230"
     ]
    }
   ],
   "source": [
    "nsteps = 200\n",
    "maxlen = masked_samples_train.shape[1]\n",
    "nchar = masked_samples_train.shape[2]\n",
    "ncls = 2\n",
    "nrec = 2\n",
    "batchsize = 200\n",
    "\n",
    "lstm_inp_drop = 0.1\n",
    "lstm_rec_drop = 0.1\n",
    "\n",
    "l_in = layers.Input(shape=(maxlen, nchar), name=\"l_in\")\n",
    "l_mask = layers.Masking(mask_value=0, name=\"l_mask\")(l_in)\n",
    "l_rec = prototype.build_rec([nsteps]*nrec, [lstm_inp_drop]*nrec, [lstm_rec_drop]*nrec)(l_mask)\n",
    "l_out = layers.TimeDistributed(\n",
    "    layers.Dense(ncls, activation='softmax'), name=\"l_out\")(l_rec)\n",
    "model = models.Model(l_in, l_out)\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "filepath = \"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "# reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3,min_lr=0.0001)\n",
    "\n",
    "callbacks_ = [checkpoint]\n",
    "\n",
    "model.fit(masked_samples_train, masked_cls_train, batch_size=batchsize, epochs=30, verbose=1,\n",
    "          validation_data=(masked_samples_test, masked_cls_test), callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[[0 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(test2_x_encoded[:1].argmin(axis=2))\n",
    "print(net2.predict(test2_x_encoded[:1]).argmax(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
